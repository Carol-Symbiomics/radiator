#' @name snp_ld
#' @title GBS/RADseq short and long distance linkage disequilibrium pruning
#' @description SNP short and long distance linkage disequilibrium pruning.
#'
#' What sets appart radiator LD pruning is the RADseq data tailored arguments.
#' First, minimize short linkage disequilibrium (LD) by
#' choosing between 5 values for \code{snp.ld} argument (see below).
#' Second, you can optionally reduce long distance LD by adjusting the argument
#' \code{ld.threshold}. Values between 0.7 and 0.9 are good starting point.
#' You can also choose to refilter the data using the outlier statistics
#' generated by the function.
#' To prune markers in long distance LD, instead of choosing randomly one SNP,
#' radiator can incorporate missing data statistics
#' to determine the best SNP to keep (see details).
#'
#' Long distance LD pruning is usually advised to avoid capturing the variance LD
#' in PCA analysis.
#'
#' This function is used internally in \href{https://github.com/thierrygosselin/radiator}{radiator}
#' and might be of interest for users.

#' @param data A tidy data set with ID (LOCUS) and POS (SNP) information.
#' \emph{How to get a tidy data frame ?}
#' Look into \pkg{radiator} \code{\link{tidy_genomic_data}}.
#' Usually the LOCUS and POS info is taken from a VCF file.
#'
#' The function also accept \code{SeqVarGDSClass} object generated
#' with the SeqArray package
#' or \pkg{radiator} \code{\link{write_seqarray}}.
#'
#' \strong{Biallelic genotypes required...}


#' @param snp.ld (character) 5 options:
#' \enumerate{
#' \item \code{snp.ld = "random"} for a random selection of 1 SNP on the read,
#' \item \code{snp.ld = "first"} for the first one on the read...,
#' \item \code{snp.ld = "last"} for the last SNP on the read and
#' \item \code{snp.ld = "middle"} for locus with > 2 SNPs/read the option to select at random
#' one SNP between the first and the last SNP on the read. If the locus as <= 2
#' SNPs on the read, the first one is selected. Note that for that last option,
#' the numbers are reported.
#' \item \code{snp.ld = "maf"} will select the SNP on the locus with the maximum global
#' Minor Allele Frequency (MAF).
#' }
#' Default: \code{snp.ld = "maf"}.

#' @param maf.data (path) When \code{snp.ld = "maf"} is selected,
#' to speed up calculations, you can provide
#' the maf information generated by the function \code{\link{filter_maf}} or
#' let this function calculates it from the data (default).
#' Designated alternate allele embedded in the data are not taken for granted
#' and this information is re-computed from the data to get actual
#' minor allele frequency. In this context, to speed up calculations,
#' the MAF is calculated only for locus with multiple SNPs .
#' Default: \code{maf.data = NULL}.
#'
#' @param ld.threshold (optional, double) The threshold to prune SNP based on
#' Long Distance Linkage Disequilibrium.
#' Default: \code{ld.threshold = NULL}.

#' @param filename (optional, character) File name prefix for file written in
#' the working directory.
#' Default: \code{filename = NULL}.


#' @param ... (optional) Advance mode that allows to pass further arguments
#' for fine-tuning the function (see details).

#' @inheritParams tidy_genomic_data

#' @export
#' @rdname snp_ld


#' @importFrom stringi stri_replace_all_fixed stri_join
#' @importFrom tibble has_name
#' @importFrom dplyr select distinct group_by sample_n summarise semi_join n_distinct

#' @references Zheng X, Levine D, Shen J, Gogarten SM, Laurie C, Weir BS.
#' (2012) A high-performance computing toolset for relatedness and principal component
#' analysis of SNP data. Bioinformatics. 28: 3326-3328.
#' doi:10.1093/bioinformatics/bts606

#' @details The function requires \href{https://github.com/zhengxwen/SNPRelate}{SNPRelate}
#' (see example below on how to install).
#'
#'
#' \strong{Advance mode, using \emph{dots-dots-dots}}
#' \itemize{
#' \item \code{long.ld.missing} (logical) With \code{long.ld.missing = TRUE}.
#' The function first generates long distance LD values between markers with
#' \emph{SNPRelate::snpgdsLDMat}.
#' SNPs in LD will be pruned based on
#' missingness.
#' e.g. if 4 SNPs are in LD, the 1 SNP selected in
#' the end is base on genotyping rate/missingness. If this statistic is equal
#' between the SNPs in LD, 1 SNP is chosen randomly.
#'
#' Using missigness add extra computational time. To speed the analysis when
#' missingness between markers is not an issue, use \code{long.ld.missing = FALSE}.
#' The function will use \emph{SNPRelate::snpgdsLDpruning}
#' to prune the dataset. SNPs in LD are selected randomly.
#' Default: \code{long.ld.missing = FALSE}.
#' \item \code{keep.gds} (logical) Default: \code{keep.gds = FALSE}, when the input data is a
#' tidy data frame of genotypes, the GDS file
#' generated for the long distance LD is removed after completion. With GDS input,
#' the GDS file is always updated and kept in the working directory.
#' \item \code{ld.figures}: (logical) Generate long distance LD statistics and
#' figures.
#' Default: \code{ld.figures = FALSE}
#' \item \code{ld.wide}: (logical) Generate a tibble with the pairwise LD values
#' observed between markers in wide format.
#' Default: \code{ld.wide = FALSE}
#' \item \code{ld.tibble}: (logical) Generate a tibble with the pairwise LD
#' values observed between markers in one column (long format).
#' Default: \code{ld.tibble = FALSE}
#' }
#'
#' @return A list in the global environment, with these objects:
#' \enumerate{
#' \item $ld.wide: a tibble with the pairwise LD values observed between markers in wide format.
#' \item $ld.tibble: a tibble with the pairwise LD values observed between markers in one column (long format).
#' \item $ld.summary: tibble with LD statistics used for the boxplot
#' \item $ld.boxplot: box plot of LD values
#' \item $whitelist.snp.ld: whitelist of markers kept after filtering for LD.
#' The argument \code{ld.threshold} must be used to generate the whitelist.
#' \item $blacklist.snp.ld: blacklist of markers prunned during the filtering
#' for LD.
#' The argument \code{ld.threshold} must be used to generate the blacklist.
#' \item $data: The filtered tidy dataset.
#' \item $gds: the path to the GDS file.
#' }

#' @examples
#' \dontrun{
#' #require(SNPRelate)
#' #To install SNPRelate:
#' #source("https://bioconductor.org/biocLite.R")
#' #biocLite("SNPRelate")
#' #library(radiator)
#' data <- radiator::tidy_vcf(
#' data = "my.vcf", strata = "my.strata.tsv",
#' vcf.metadata = FALSE, vcf.stats = TRUE, verbose = TRUE)
#'
#' # short distance LD, no long distance LD:
#' check.short.ld <- radiator::snp_ld(
#' data = data$tidy.data,
#' snp.ld = "maf")
#'
#' # short distance LD and long distance LD:
#' pruned.ld <- radiator::snp_ld(
#' data = data$tidy.data,
#' snp.ld = "maf", ld.threshold = 0.8)
#' }


#' @author Thierry Gosselin \email{thierrygosselin@@icloud.com}


snp_ld <- function(
  data,
  snp.ld = "maf",
  maf.data = NULL,
  ld.threshold = NULL,
  parallel.core = parallel::detectCores() - 1,
  filename = NULL,
  ...
) {

  # # testing
  # data <- res$vcf.connection
  # snp.ld = "maf"
  # maf.data = NULL
  # ld.threshold = 0.8
  # filename = NULL
  # parallel.core = parallel::detectCores() - 1
  # # ...
  # keep.gds <- TRUE
  # ld.figures <- TRUE
  # ld.wide <- FALSE
  # ld.tibble <- FALSE
  # manhattan.plot <- FALSE
  # long.ld.missing = FALSE

  timing <- proc.time()
  opt.change <- getOption("width")
  options(width = 70)
  res.snp.ld <- list()# to store the output

  # dotslist -------------------------------------------------------------------
  radiator.dots <- list(...)
  want <- c("long.ld.missing", "keep.gds", "ld.wide", "ld.tibble", "ld.figures", "manhattan.plot")
  unknowned_param <- setdiff(names(radiator.dots), want)

  if (length(unknowned_param) > 0) {
    stop("Unknowned \"...\" parameters ",
         stringi::stri_join(unknowned_param, collapse = " "))
  }

  long.ld.missing <- radiator.dots[["long.ld.missing"]]
  keep.gds <- radiator.dots[["keep.gds"]]
  ld.wide <- radiator.dots[["ld.wide"]]
  ld.tibble <- radiator.dots[["ld.tibble"]]
  ld.figures <- radiator.dots[["ld.figures"]]
  manhattan.plot <- radiator.dots[["manhattan.plot"]]

  if (is.null(long.ld.missing)) long.ld.missing <- FALSE
  if (is.null(keep.gds)) keep.gds <- FALSE
  if (is.null(ld.wide)) ld.wide <- FALSE
  if (is.null(ld.tibble)) ld.tibble <- FALSE
  if (is.null(ld.figures)) ld.figures <- FALSE
  if (is.null(manhattan.plot)) manhattan.plot <- FALSE
  if (is.null(ld.threshold)) long.ld.missing <- FALSE

  # match arg ------------------------------------------------------------------
  snp.ld <- match.arg(snp.ld, c("first", "random", "last", "middle", "maf"))

  # Checking for missing and/or default arguments ------------------------------
  if (missing(data)) stop("Input file missing")

  # Filename -------------------------------------------------------------------
  file.date <- format(Sys.time(), "%Y%m%d@%H%M")
  if (is.null(filename)) {
    write.ld <- FALSE
    filename <- stringi::stri_join("radiator_", file.date, ".ld")
  } else {
    write.ld <- TRUE
    filename.problem <- file.exists(filename)
    if (filename.problem) {
      filename <- stringi::stri_join(filename, "_", file.date, ".ld")
    } else {
      filename <- stringi::stri_join(filename, ".ld")
    }
  }

  filename.gds <- stringi::stri_join(filename, ".gds")
  # Import data ---------------------------------------------------------------
  data.type <- radiator::detect_genomic_format(data)

  if (data.type == "tbl_df") {
    if (is.vector(data)) {
      data <- radiator::tidy_wide(data = data, import.metadata = FALSE)
    }

    markers <- dplyr::select(data, MARKERS, CHROM, LOCUS, POS) %>%
      dplyr::distinct(MARKERS, .keep_all = TRUE)

    # Check that fiel format as ID and POS -------------------------------------
    if (!tibble::has_name(data, "LOCUS") && !tibble::has_name(data, "POS")) {
      stop("snp.ld is only available for VCF file and/or files with ID and POS info")
    }

    if (!is.null(ld.threshold)) {# for long distance LD pruning
      # Check that snprelate is installed
      if (!requireNamespace("SNPRelate", quietly = TRUE)) {
        stop('To install SNPRelate:\n
         source("https://bioconductor.org/biocLite.R")
         biocLite("SNPRelate")')
      }
      # Check if data is biallelic -------------------------------------------------
      biallelic <- radiator::detect_biallelic_markers(data = data)
      if (!biallelic) stop("Long distance LD: biallelic genotypes required")

      # Generating SNPRelate data --------------------------------------------------
      message("Preparing the data...")
      res.snp.ld$data.gds <- radiator::write_snprelate(
        data = data,
        biallelic = TRUE,
        filename = filename,
        verbose = FALSE)
      if (keep.gds) {
        message("SNPRelate GDS file generated: ", filename.gds)
        message("To close the connection use SNPRelate::snpgdsClose(filename)")
      }
    }
  } else {
    res.snp.ld$data.gds <- data
    data <- markers <- tibble::tibble(
      VARIANT_ID = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/VARIANT_ID")),
      MARKERS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/MARKERS")),
      CHROM = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/CHROM")),
      LOCUS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/LOCUS")),
      POS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.snp.ld$data.gds, path = "radiator/markers.meta/POS"))
    )
  }

  message("Minimizing short distance LD...")
  message("    snp.ld = ", snp.ld)

  snp.locus <- dplyr::distinct(data, LOCUS, MARKERS, .keep_all = TRUE) %>%
    dplyr::arrange(LOCUS, MARKERS)
  locus.stats <- dplyr::group_by(.data = snp.locus, LOCUS) %>%
    dplyr::tally(.) %>%
    dplyr::rename(SNP_N = n) %>%
    dplyr::group_by(SNP_N) %>%
    dplyr::tally(.)

  if (nrow(locus.stats) > 1) {
    range.number.snp.locus <- range(locus.stats$SNP_N, na.rm = TRUE)
    message("    The range in the number of SNP/locus is: ", stringi::stri_join(range.number.snp.locus, collapse = "-"))
    # Random selection ---------------------------------------------------------
    if (snp.ld == "random") {
      snp.select <- snp.locus %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::sample_n(tbl = ., size = 1, replace = FALSE)
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      message("    Number of SNP before = ", snp.before)
      message("    Number of SNP removed = ", snp.before - snp.after)
      message("    Number of SNP after = ", snp.after)
    }#End snp random

    # Fist SNP on the read -----------------------------------------------------
    if (snp.ld == "first") {
      snp.select <- snp.locus %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::summarise(POS = min(POS))
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      message("    Number of SNP before = ", snp.before)
      message("    Number of SNP removed = ", snp.before - snp.after)
      message("    Number of SNP after = ", snp.after)
    }#End snp first

    # Last SNP on the read -----------------------------------------------------
    if (snp.ld == "last") {
      snp.select <- snp.locus %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::summarise(POS = max(POS))
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      message("    Number of SNP before = ", snp.before)
      message("    Number of SNP removed = ", snp.before - snp.after)
      message("    Number of SNP after = ", snp.after)
    }#End snp last

    # Middle SNP on the read -----------------------------------------------------
    if (snp.ld == "middle") {
      snp.locus.prep <- dplyr::group_by(.data = snp.locus, LOCUS) %>%
        dplyr::tally(.)

      pick.middle <- snp.locus.prep %>%
        dplyr::filter(n > 2) %>%
        dplyr::select(LOCUS)

      if (nrow(pick.middle) == 0) {
        message("IMPORTANT: the data doesn't have more than 3 SNPs per locus")
        message("    First SNP will be selected instead...")
        snp.select <- snp.locus %>%
          dplyr::group_by(LOCUS) %>%
          dplyr::summarise(POS = min(POS))
      } else {

        # For locus with <= 2 SNPs/read just keep the first one.
        keep.first <- snp.locus.prep %>%
          dplyr::filter(n <= 2) %>%
          dplyr::select(LOCUS)
        message("    Number of locus with first SNP selected: ", nrow(keep.first))
        keep.first.select <- snp.locus %>%
          dplyr::filter(LOCUS %in% keep.first$LOCUS) %>%
          dplyr::group_by(LOCUS) %>%
          dplyr::summarise(POS = min(POS))

        pick.middle.select <- snp.locus %>%
          dplyr::filter(LOCUS %in% pick.middle$LOCUS) %>%
          dplyr::group_by(LOCUS) %>%
          dplyr::filter(POS != min(POS)) %>% # remove the first SNP
          dplyr::filter(POS != max(POS)) %>% # remove the last SNP
          dplyr::sample_n(tbl = ., size = 1, replace = FALSE) # pick one at random

        message("    Number of locus with random middle SNP selected: ", nrow(pick.middle))
        snp.select <- dplyr::bind_rows(keep.first.select, pick.middle.select) %>%
          dplyr::arrange(LOCUS, POS)
      }
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      message("    Number of SNP before = ", snp.before)
      message("    Number of SNP removed = ", snp.before - snp.after)
      message("    Number of SNP after = ", snp.after)
    }#End snp middle

    # SNP with max MAF on the read -----------------------------------------------
    if (snp.ld == "maf") {
      # snp.select: markers that doesnt require filtering for MAF/MAC
      # because only 1 SNP/locus
      snp.select <- dplyr::group_by(.data = snp.locus, LOCUS) %>%
        dplyr::tally(.) %>%
        dplyr::filter(n == 1) %>%
        dplyr::left_join(snp.locus, by = "LOCUS") %>%
        dplyr::select(-n) %>%
        dplyr::distinct(MARKERS, .keep_all = TRUE)


      if (is.null(maf.data)) {
        if (data.type == "tbl_df") {
          # calculate GLOBAL MAF per SNP/LOCUS
          if (tibble::has_name(data, "GT_BIN")) {
            markers.df <- dplyr::distinct(snp.locus, MARKERS) %>%
              dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS)
            n.markers <- nrow(markers.df)

            global_maf <- function(x) {
              maf.data <- dplyr::group_by(x, MARKERS) %>%
                dplyr::summarise(
                  N = as.numeric(2 * n()),
                  PP = as.numeric(2 * length(GT_BIN[GT_BIN == 0])),
                  PQ = as.numeric(length(GT_BIN[GT_BIN == 1])),
                  QQ = as.numeric(2 * length(GT_BIN[GT_BIN == 2]))
                ) %>%
                # need this step because seen cases where 2 is not the minor allele...
                dplyr::mutate(
                  PP = PP + PQ,
                  QQ = QQ + PQ,
                  ALT = dplyr::if_else(PP < QQ, PP, QQ)) %>%
                dplyr::mutate(
                  MAF_GLOBAL = (ALT / N),
                  N = NULL, PP = NULL, QQ = NULL, PQ = NULL, ALT = NULL) %>%
                dplyr::ungroup(.)

              return(maf.data)
            }#End global_maf

            if (n.markers > 10000) {
              split.vec <- markers.df %>%
                dplyr::mutate(SPLIT_VEC = split_vec_row(
                  markers.df,
                  cpu.rounds = ceiling(n.markers/10000),
                  parallel.core = parallel.core))

              maf.data <- data %>%
                dplyr::filter(!is.na(GT_BIN)) %>%
                dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS) %>%
                dplyr::left_join(split.vec, by = "MARKERS") %>%
                split(x = ., f = .$SPLIT_VEC) %>%
                .radiator_parallel_mc(
                  X = .,
                  FUN = global_maf,
                  mc.cores = parallel.core
                ) %>%
                dplyr::bind_rows(.)
              markers.df <- split.vec <- NULL
            } else {
              maf.data <- global_maf(
                x = dplyr::filter(data, !is.na(GT_BIN)) %>%
                  dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS)
              )
            }
          } else {
            maf.data <- data %>%
              dplyr::filter(GT != "000000") %>%
              dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS) %>%
              dplyr::select(MARKERS, INDIVIDUALS, GT) %>%
              dplyr::mutate(
                A1 = stringi::stri_sub(GT, 1, 3),
                A2 = stringi::stri_sub(GT, 4,6)
              ) %>%
              dplyr::select(MARKERS, INDIVIDUALS, A1, A2) %>%
              tidyr::gather(data = ., key = ALLELES, value = GT, -c(MARKERS, INDIVIDUALS)) %>%
              dplyr::group_by(MARKERS, GT) %>%
              dplyr::tally(.) %>%
              dplyr::group_by(MARKERS) %>%
              dplyr::mutate(n.al.tot = sum(n)) %>%
              dplyr::filter(n == min(n)) %>%
              dplyr::distinct(MARKERS, .keep_all = TRUE) %>%
              dplyr::summarise(MAF_GLOBAL = n / n.al.tot) %>%
              dplyr::ungroup(.) %>%
              dplyr::select(MARKERS, MAF_GLOBAL)
          }

          snp.select.maf <- snp.locus %>%
            dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS) %>%
            dplyr::left_join(maf.data, by = "MARKERS") %>%
            dplyr::group_by(LOCUS) %>%
            dplyr::filter(MAF_GLOBAL == max(MAF_GLOBAL)) %>%
            dplyr::ungroup(.) %>%
            dplyr::distinct(LOCUS, .keep_all = TRUE)

        } else {
          # Note to myself: instead of creating a new object (maf.data),
          # include the info in the markers obj
          n.markers <- dplyr::n_distinct(markers$MARKERS)
          markers <- suppressWarnings(
            markers %>%
              dplyr::bind_cols(
                SeqArray::seqAlleleCount(
                  gdsfile = res.snp.ld$data.gds,
                  ref.allele = NULL,
                  .progress = TRUE,
                  parallel = parallel.core) %>%
                  unlist(.) %>%
                  matrix(
                    data = .,
                    nrow = n.markers, ncol = 2, byrow = TRUE,
                    dimnames = list(rownames = markers$MARKERS,
                                    colnames = c("REF_COUNT", "ALT_COUNT"))) %>%
                  tibble::as_tibble(.)) %>%
              dplyr::mutate(
                # MAC or MAF here it's the same
                MAF_GLOBAL = dplyr::if_else(ALT_COUNT < REF_COUNT, ALT_COUNT, REF_COUNT),
                ALT_COUNT = NULL,
                REF_COUNT = NULL)
          )
        }
      } else {
        if (is.vector(maf.data)) {
          markers <- suppressWarnings(
            markers %>%
              dplyr::bind_cols(
                readr::read_tsv(
                  file = maf.data,
                  col_types = readr::cols(.default = readr::col_character())) %>%
                  dplyr::select(MARKERS, MAF_GLOBAL) %>%
                  dplyr::distinct(MARKERS, .keep_all = TRUE)
              ))
        } else {
          markers <- suppressWarnings(
            markers %>%
              dplyr::bind_cols(
                maf.data %>%
                  dplyr::select(dplyr::one_of(c("MARKERS", "MAF_GLOBAL"))) %>%
                  dplyr::distinct(MARKERS, .keep_all = TRUE)))
        }
      }
      # alternative that doesnt require snp.select.maf
      snp.select <- markers %>%
        dplyr::filter(!MARKERS %in% snp.select$MARKERS) %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::filter(MAF_GLOBAL == max(MAF_GLOBAL)) %>%
        dplyr::ungroup(.) %>%
        dplyr::select(-MAF_GLOBAL) %>%
        dplyr::distinct(LOCUS, .keep_all = TRUE) %>%
        dplyr::bind_rows(snp.select)

      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      n.markers <- stringi::stri_join(snp.before, snp.before - snp.after, snp.after, sep = "/")
      message("    Number of markers before/blacklisted/after: ", n.markers)
      snp.locus <- markers <- NULL
    }#End snp maf


    # filtering the VCF to minimize LD -----------------------------------------
    # data <- dplyr::semi_join(data, snp.select, by = c("LOCUS", "POS"))
    if (data.type == "tbl_df") {
      data <- dplyr::filter(data, MARKERS %in% snp.select$MARKERS)
    } else {
      res.snp.ld$whitelist.snp.ld <- snp.select
      res.snp.ld$blacklist.snp.ld <- dplyr::filter(data, !MARKERS %in% snp.select$MARKERS)
      data <- res.snp.ld$whitelist.snp.ld

      # updating the GDS object ------------------------------------------------
      # radiator.gds <- gdsfmt::index.gdsn(
      #   node = res.snp.ld$data.gds, path = "radiator/markers.meta")
      # gdsfmt::add.gdsn(
      #   node = radiator.gds,
      #   name = "FILTER_SHORT_LD",
      #   val = data$FILTER_SHORT_LD,
      #   replace = TRUE,
      #   compress = "ZIP_RA",
      #   closezip = TRUE)
      SeqArray::seqSetFilter(object = res.snp.ld$data.gds,
                             variant.id = data$VARIANT_ID,
                             verbose = FALSE)

    }
    message("    Filtering the dataset to minimize LD by keeping only 1 SNP per locus")
  } else {
    message("    There is no variation in the number of SNP/locus across the data")
  }
  # Note to myself:
  # locus.stats: this stats could be written in directory or output in res
  snp.select <-  locus.stats <- NULL


  # Long distance LD pruning ---------------------------------------------------

  if (!is.null(ld.threshold)) {
    # updating GDS object
    want <- c("VARIANT_ID", "MARKERS", "CHROM", "LOCUS", "POS")
    markers <- variant.id.select <- suppressWarnings(
      dplyr::select(data, dplyr::one_of(want)) %>%
        dplyr::distinct(MARKERS, .keep_all = TRUE) %>%
        dplyr::arrange(VARIANT_ID))


    # # Test with 10000 markers
    # random.markers <- 5000
    # markers <- variant.id.select <- dplyr::sample_n(
    #   tbl = variant.id.select, size = random.markers) %>%
    #   dplyr::arrange(VARIANT_ID)

    variant.id.select <- variant.id.select %>%
      dplyr::select(VARIANT_ID) %>%
      purrr::flatten_int(.)

    # Apply the filter on the gds ...
    # SeqArray::seqSetFilter(object = res.snp.ld$data.gds,
    #                        variant.id = variant.id.select, verbose = FALSE)
    n.markers <- length(variant.id.select)
    if (long.ld.missing) {
      message("Long distance LD pruning with missing data")
      message("Computing LD...")
      res.snp.ld$ld.tibble <- SNPRelate::snpgdsLDMat(
        gdsobj = res.snp.ld$data.gds,
        snp.id = variant.id.select,
        sample.id = NULL,
        slide = -1,
        mat.trim = FALSE,
        method = "r", #composite and corr option are the same with 0, 1, 2 gt coding
        num.thread = parallel.core,
        with.id = TRUE,
        verbose = FALSE) %$% LD
      # names(res.snp.ld$ld.tibble)
      # markers$SNPRELATE <- res.snp.ld$ld.tibble$snp.id
      # res.snp.ld$ld.tibble <- res.snp.ld$ld.tibble$LD

      # work on the output ---------------------------------------------------------
      # long.distance.ld <- long.distance.ld^2
      colnames(res.snp.ld$ld.tibble) <- rownames(res.snp.ld$ld.tibble) <- markers$MARKERS

      # Full matrix
      if (ld.wide) {
        # generate a tibble
        filename.ld.wide <- stringi::stri_join(filename, ".wide")
        message("Writing LD wide tibble file: ", filename.ld.wide)
        radiator::write_rad(
          data = dplyr::bind_cols(tibble::data_frame(
            MARKERS_A = rownames(res.snp.ld$ld.tibble)),
            tibble::as_data_frame(res.snp.ld$ld.tibble)),
          path = filename.ld.wide)
      }

      # LD tibble long...
      # Here we want the tibble in long format with LD values in one column
      message("Generating LD tibble...")
      # we don't need the full matrix
      res.snp.ld$ld.tibble[lower.tri(res.snp.ld$ld.tibble, diag = TRUE)] <- rlang::na_dbl

      # stats and figures----------------------------------------------------------------------
      if (ld.figures) {
        message("Generating statistics")
        res.snp.ld$ld.summary <- tibble::tibble(
          LD = as.vector(res.snp.ld$ld.tibble[!is.na(res.snp.ld$ld.tibble)])) %>%
          dplyr::summarise(
            MIN = min(LD, na.rm = TRUE),
            Q25 = stats::quantile(LD, 0.25, na.rm = TRUE),
            MEDIAN = stats::median(LD, na.rm = TRUE),
            Q75 = stats::quantile(LD, 0.75, na.rm = TRUE),
            MAX = max(LD, na.rm = TRUE),
            IQR = stats::IQR(LD, na.rm = TRUE)
          ) %>%
          dplyr::mutate(
            OUTLIERS_LOW = Q25 - (1.5 * IQR),
            OUTLIERS_HIGH =  Q75 + (1.5 * IQR),
            GROUP = 1
          )

        if (res.snp.ld$ld.summary$OUTLIERS_LOW < 0) {
          res.snp.ld$ld.summary$OUTLIERS_LOW <- res.snp.ld$ld.summary$MIN
        }

        message("Generating figures...")
        res.snp.ld$ld.boxplot <- boxplot_stats(
          data = res.snp.ld$ld.summary,
          title = "Markers long distance linkage disequilibrium (LD)",
          x.axis.title = NULL,
          y.axis.title = "Long distance linkage disequilibrium (r)",
          bp.filename = "ld.boxplot.pdf")

        # res.snp.ld$ld.no.outliers.tibble <- dplyr::filter(res.snp.ld$ld.tibble, LD < res.snp.ld$ld.summary$OUTLIERS_HIGH & LD > res.snp.ld$ld.summary$OUTLIERS_LOW)

        # Note to myself : interesting but not sure worth the time exploring...


        # res.snp.ld$ld.no.outliers.summary <- tibble::tibble(
        #   x = 1,
        #   MIN = min(res.snp.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
        #   Q25 = stats::quantile(res.snp.ld$ld.no.outliers.tibble$LD, 0.25, na.rm = TRUE),
        #   MEDIAN = stats::median(res.snp.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
        #   Q75 = stats::quantile(res.snp.ld$ld.no.outliers.tibble$LD, 0.75, na.rm = TRUE),
        #   MAX = max(res.snp.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
        #   IQR = stats::IQR(res.snp.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
        #   OUTLIERS_LOW = Q25 - (1.5 * IQR),
        #   OUTLIERS_HIGH =  Q75 + (1.5 * IQR)
        # )
        # if (res.snp.ld$ld.no.outliers.summary$OUTLIERS_LOW < 0) res.snp.ld$ld.no.outliers.summary$OUTLIERS_LOW <- res.snp.ld$ld.no.outliers.summary$MIN
        #
        # element.text <- ggplot2::element_text(size = 10,
        #                                       family = "Helvetica", face = "bold")
        #
        # res.snp.ld$ld.boxplot.no.outliers <- ggplot2::ggplot(
        #   data = res.snp.ld$ld.no.outliers.summary, ggplot2::aes(x)) +
        #   ggplot2::geom_boxplot(
        #     ggplot2::aes(ymin = MIN, lower = Q25, middle = MEDIAN,
        #                  upper = Q75, ymax = MAX), stat = "identity") +
        #   ggplot2::labs(
        #     y = "Long distance linkage disequilibrium",
        #     title = "Markers long distance linkage disequilibrium (LD)") +
        #   ggplot2::theme_bw() +
        #   ggplot2::theme(
        #     plot.title = ggplot2::element_text(size = 12, family = "Helvetica", face = "bold", hjust = 0.5),
        #     legend.position = "none",
        #     axis.title.x = ggplot2::element_blank(),
        #     axis.title.y = element.text,
        #     axis.text.x = ggplot2::element_blank(),
        #     axis.ticks.x = ggplot2::element_blank()
        #   )
        # element.text <- NULL
        # print(res.snp.ld$ld.boxplot.no.outliers)
        # suppressMessages(ggplot2::ggsave(
        #   filename = "ld.no.outliers.boxplot.pdf",
        #   # filename = file.path(path.folder.coverage, "plot.coverage.boxplot.pdf"),
        #   plot = res.snp.ld$ld.boxplot.no.outliers,
        #   width = 15, height = 20,
        #   dpi = 300, units = "cm", useDingbats = FALSE))


        # res.snp.ld$ld.manhattan.plot
        # if (manhattan.plot) {
        #   res.snp.ld$ld.manhattan.plot <- res.snp.ld$ld.tibble %>%
        #     # dplyr::mutate(X = "1") %>%
        #     dplyr::group_by(LD) %>%
        #     dplyr::tally(.) %>%
        #     dplyr::ungroup(.) %>%
        #     dplyr::mutate(X = "1") %>%
        #     ggplot2::ggplot(data = .,
        #                     ggplot2::aes(x = X, y = LD, size = n)) +
        #     ggplot2::geom_jitter(alpha = 0.3, stat = "identity") +
        #     ggplot2::labs(y = "LD") +
        #     ggplot2::scale_size_area(name = "Pairs of markers", max_size = 6) +
        #     ggplot2::theme_light() +
        #     ggplot2::theme(
        #       # legend.position = "none",
        #       panel.grid.minor.x = ggplot2::element_blank(),
        #       panel.grid.major.x = ggplot2::element_blank(),
        #       # panel.grid.major.y = element_blank(),
        #       axis.title.x = ggplot2::element_blank(),
        #       axis.text.x = ggplot2::element_blank(),
        #       axis.title.y = ggplot2::element_text(size = 10, family = "Helvetica", face = "bold"),
        #       axis.text.y = ggplot2::element_text(size = 8, family = "Helvetica")
        #     )
        #
        #   suppressMessages(ggplot2::ggsave(
        #     filename = "ld.manhattan.plot.png",
        #     plot = res.snp.ld$ld.manhattan.plot,
        #     width = 15, height = 20,
        #     dpi = 100, units = "cm"#useDingbats = FALSE
        #   ))
        # }
      }

      # Generate the missingness stats -----------------------------------------
      message("Generate missingness stats")
      if (data.type == "tbl_df") {
        if (tibble::has_name(data, "GT")) {
          res.snp.ld$markers.missing <- dplyr::filter(data, GT != "000000") %>%
            dplyr::group_by(MARKERS) %>%
            dplyr::summarise(GENOTYPED_PROP = length(GT) / n.ind)
        } else {
          res.snp.ld$markers.missing <- dplyr::filter(data, !is.na(GT_BIN)) %>%
            dplyr::group_by(MARKERS) %>%
            dplyr::summarise(GENOTYPED_PROP = length(GT_BIN) / n.ind)
        }
      } else {
        res.snp.ld$markers.missing <- tibble::tibble(
          MARKERS = markers$MARKERS,
          MISSING_PROP = (SeqArray::seqMissing(
            gdsfile = res.snp.ld$data.gds,
            per.variant = TRUE, .progress = TRUE, parallel = parallel.core))) %>%
          dplyr::mutate(GENOTYPED_PROP = 1 - MISSING_PROP, MISSING_PROP = NULL)
        # check.filter.gds <- SeqArray::seqGetFilter(gdsfile = res.snp.ld$data.gds) %$% variant.sel
      }

      # remove SNPRelate GDS object
      # if (!keep.gds) {
      #   res.snp.ld$data.gds <- NULL
      #   message("Removing GDS file")
      #   if (file.exists(filename.gds)) file.remove(filename.gds)
      # }

      # Pruning the SNPs -----------------------------------------------------------
      message("Pruning markers in long distance LD...")

      # These LD values are not used anyway during the pruning
      # pryr::object_size(res.snp.ld$ld.tibble)
      res.snp.ld$ld.tibble[res.snp.ld$ld.tibble <= ld.threshold] <- rlang::na_dbl
      # pryr::object_size(res.snp.ld$ld.tibble)
      # remove rows and cols with all missing values
      res.snp.ld$ld.tibble <- res.snp.ld$ld.tibble[rowSums(res.snp.ld$ld.tibble, na.rm = TRUE) > 0, colSums(res.snp.ld$ld.tibble, na.rm = TRUE) > 0]
      # pryr::object_size(res.snp.ld$ld.tibble)
      res.snp.ld$ld.tibble <- ld2df(x = res.snp.ld$ld.tibble)
      # pryr::object_size(res.snp.ld$ld.tibble)

      ld.markers <- ld_pruning(
        ld.tibble = res.snp.ld$ld.tibble,
        stats = res.snp.ld$markers.missing,
        ld.threshold = ld.threshold
      )
      # names(ld.markers)
      if (!ld.tibble) res.snp.ld$ld.tibble <- NULL
      message("Generating whitelist and blacklist of markers")
      markers <- markers %>%
        dplyr::mutate(
          FILTER_LONG_LD = dplyr::if_else(
            MARKERS %in% ld.markers$blacklist.markers$MARKERS, FALSE, TRUE))
      ld.markers <- NULL

    } else {
      # Pruning with SNPRelate::snpgdsLDpruning --------------------------------------
      # problem with this one is that missigness is unaccounted for during SNP selection
      # SNPs are randomly selected...
      message("Long distance LD pruning WITHOUT missing data stats")
      # ld.threshold <- 0.8
      ld.markers <- list()

      # TODO:
      # parallelize with and without the use of missing
      # with SNPRelate::snpgdsLDpruning, split a whitelist of markers based
      # on chromosome

      n.chrom <- dplyr::n_distinct(markers$CHROM)

      if (parallel.core > 1) {
        prune_ld_par <- function(chrom.snp.select, data, threshold) {
          pruned.snp <- SNPRelate::snpgdsLDpruning(
            gdsobj = data,
            snp.id = chrom.snp.select$VARIANT_ID,
            autosome.only = FALSE,
            remove.monosnp = TRUE,
            maf = NaN,
            missing.rate = NaN,
            method = "r",
            ld.threshold = threshold,
            num.thread = 1,
            verbose = TRUE) %>%
            purrr::flatten_int(.)
          return(pruned.snp)
        }#End prune_ld_par


        # ld.markers$whitelist.markers <-
        #   split(x = x, f = split.vec) %>%
        #   .radiator_parallel(
        #     X = ., FUN = clean, mc.cores = parallel.core) %>%
        #   purrr::flatten_int(.)

        # sample.chrom <- sample(x = unique(markers$CHROM), size = 11)
        #
        # check <- dplyr::left_join(
        #   dplyr::select(markers, CHROM, VARIANT_ID),
        #   dplyr::distinct(markers, CHROM) %>%
        #     dplyr::mutate(
        #       SPLIT_VEC = split_vec_row(x = ., cpu.rounds = 10, parallel.core = parallel.core)
        #     )
        #   , by = "CHROM") %>%
        #   dplyr::filter(CHROM %in% sample.chrom) %>%
        #   dplyr::select(-CHROM) %>%
        #   split(x = ., f = .$SPLIT_VEC) %>%
        #   .radiator_parallel_mc(
        #     X = .,
        #     FUN = prune_ld_par,
        #     mc.cores = parallel.core,
        #     data = res.snp.ld$data.gds, threshold = ld.threshold
        #   ) %>%
        #   purrr::flatten_int(.)
        # length(unique(check$CHROM))


      } else {



        ld.markers$whitelist.markers <- SNPRelate::snpgdsLDpruning(
          gdsobj = res.snp.ld$data.gds,
          snp.id = variant.id.select,
          autosome.only = FALSE,
          remove.monosnp = TRUE,
          maf = NaN,
          missing.rate = NaN,
          method = "r",
          ld.threshold = ld.threshold,
          num.thread = 1,
          verbose = TRUE) %>%
          purrr::flatten_int(.)
      }


      ld.markers$blacklist.markers <- purrr::keep(
        .x = variant.id.select,
        .p = !variant.id.select %in% ld.markers$whitelist.markers)
      markers <- markers %>%
        dplyr::mutate(
          FILTER_LONG_LD = dplyr::if_else(
            VARIANT_ID %in% ld.markers$whitelist.markers, TRUE, FALSE))
      ld.markers <- NULL
      # check <- dplyr::filter(markers, FILTER_LONG_LD)
    }

    res.snp.ld$whitelist.snp.ld <- dplyr::filter(markers, FILTER_LONG_LD)
    message("    Number of SNPs after pruning for long distance LD: ",
            nrow(res.snp.ld$whitelist.snp.ld))

    res.snp.ld$blacklist.snp.ld <- dplyr::filter(markers, !FILTER_LONG_LD)

    message("    Number of prunned SNPs based on long distance LD: ",
            nrow(res.snp.ld$blacklist.snp.ld))

    # if (nrow(res.snp.ld$blacklist.snp.ld) > 0) {
    #   readr::write_tsv(x = res.snp.ld$blacklist.snp.ld,
    #                    path = "blacklist.snp.long.dist.ld.tsv")
    # }

    # updating the GDS object ------------------------------------------------
    if (data.type == "tbl_df") {
      data <- dplyr::filter(data, MARKERS %in% res.snp.ld$whitelist.snp.ld$MARKERS)
    } else {
      # radiator.gds <- gdsfmt::index.gdsn(
      # node = res.snp.ld$data.gds, path = "radiator/markers.meta")
      # long.ld <- tibble::tibble(MARKERS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = radiator.gds, path = "MARKERS"))) %>%
      # dplyr::mutate(FILTER_LONG_LD = dplyr::if_else(MARKERS %in% res.snp.ld$whitelist.snp.ld$MARKERS, TRUE, FALSE))
      # check <- dplyr::filter(long.ld, FILTER_LONG_LD)
      # gdsfmt::add.gdsn(
      #   node = radiator.gds,
      #   name = "FILTER_LONG_LD",
      #   val = long.ld$FILTER_LONG_LD,
      #   replace = TRUE,
      #   compress = "ZIP_RA",
      #   closezip = TRUE)
      # long.ld <- NULL


      SeqArray::seqSetFilter(object = res.snp.ld$data.gds,
                             variant.id = res.snp.ld$whitelist.snp.ld$VARIANT_ID,
                             verbose = FALSE)

    }
  }#End long distance LD pruning
  message("    Generating whitelist and blacklist of markers")
  message("\nComputation time for LD: ", round((proc.time() - timing)[[3]]), " sec")
  options(width = opt.change)

  if (data.type == "tbl_df") {
    return(data)
  } else {
    return(res.snp.ld)
  }
}#End snp_ld


# Internal nested functions: ---------------------------------------------------

# melt the LD matrice into a data frame --------------------------------------
#' @title ld2df
#' @description melt the LD matrice into a data frame
#' @rdname ld2df
#' @export
#' @keywords internal
ld2df <- function(x) {
  # x <- ld.upper.matrix
  x <- as.matrix(x)
  # diag(x) <- NA
  # x[lower.tri(x)] <- NA
  x <- dplyr::bind_cols(tibble::data_frame(MARKERS_A = rownames(x)),
                        tibble::as_data_frame(x)) %>%
    data.table::as.data.table(.) %>%
    data.table::melt.data.table(
      data = ., id.vars = "MARKERS_A", variable.name = "MARKERS_B", value.name = "LD",
      variable.factor = FALSE) %>%
    tibble::as_data_frame(.) %>%
    dplyr::filter(!is.na(LD)) %>%
    dplyr::arrange(dplyr::desc(LD))
  return(x)
}#End distance2df

# ld_pruning  ------------------------------------------------------------------

#' @name ld_pruning
#' @title Prune dataset based on LD.
#' @description Used internally in \href{https://github.com/thierrygosselin/radiator}{radiator}
#' Prune dataset based on LD. Use missingness to keep 1 SNP.

#' @param ld.tibble (path) The markers LD pairwise data.
#' Default: \code{ld.tibble = NULL}.
#' @param stats (path) The markers missingness info statistics.
#' Default: \code{stats = NULL}.
#' @param ld.threshold (double) The threshold to prune SNPs in LD.
#' Default: \code{ld.threshold = 0.8}.

#' @return A list with blacklisted SNPs.  Write the blacklist in the working
#' directory.
#' @export
#' @keywords internal
#' @rdname remove_duplicates
#' @author Thierry Gosselin \email{thierrygosselin@@icloud.com}

ld_pruning <- function(
  ld.tibble = NULL,
  stats = NULL,
  ld.threshold = 0.8
) {
  #test
  # ld.tibble = res$ld.tibble
  # stats = res$markers.missing
  # ld.threshold = 0.8

  ld.tibble <- dplyr::filter(ld.tibble, LD > ld.threshold)

  if (nrow(ld.tibble) > 0) {
    markers.ld.list <- tibble::data_frame(
      MARKERS = c(ld.tibble$MARKERS_A, ld.tibble$MARKERS_B)) %>%
      dplyr::group_by(MARKERS) %>%
      dplyr::tally(.) %>%
      dplyr::ungroup(.) %>%
      dplyr::arrange(dplyr::desc(n)) %>%
      dplyr::distinct(MARKERS) %>%
      purrr::flatten_chr(.)

    # test <- unique(c(ld.tibble$MARKERS_A, ld.tibble$MARKERS_B))
    # we want to have them ordered from highest to lowest hence the appraoch above...

    geno.stats <- dplyr::filter(stats, MARKERS %in% markers.ld.list)

    res <- list(blacklist.markers = tibble::tibble(MARKERS = character(0)),
                whitelist.markers = tibble::tibble(MARKERS = character(0)))

    for (i in markers.ld.list) {
      # i <- markers.ld.list[1]
      dups <- dplyr::filter(ld.tibble, MARKERS_A %in% i | MARKERS_B %in% i)
      dups <- sort(unique(c(dups$MARKERS_A, dups$MARKERS_B)))

      # find all duplicates associated with the network
      new.dups <- 0L
      while(length(new.dups) > 0) {
        new.dups <- dplyr::filter(ld.tibble, MARKERS_A %in% dups | MARKERS_B %in% dups)
        new.dups <- sort(unique(c(new.dups$MARKERS_A, new.dups$MARKERS_A)))
        new.dups <- purrr::keep(.x = new.dups, .p = !new.dups %in% dups)
        if (length(new.dups) > 0) {
          dups <- c(dups, new.dups)
        }
      }
      dups <- tibble::data_frame(MARKERS = dups)

      if (nrow(res$blacklist.markers) > 0) {
        dups <- dplyr::filter(dups, !MARKERS %in% res$blacklist.markers$MARKERS)
      }

      if (nrow(dups) > 0) {
        whitelist.markers <- dups %>%
          dplyr::left_join(geno.stats, by = "MARKERS") %>%
          dplyr::filter(GENOTYPED_PROP == max(GENOTYPED_PROP)) %>%
          dplyr::sample_n(tbl = ., size = 1) %>% # make sure only 1 is selected
          dplyr::select(MARKERS)

        if (nrow(whitelist.markers) > 0) res$whitelist.markers <- dplyr::bind_rows(res$whitelist.markers, whitelist.markers)

        blacklist.markers <- dplyr::filter(dups, !MARKERS %in% whitelist.markers$MARKERS) %>%
          dplyr::select(MARKERS)

        if (nrow(blacklist.markers) > 0) res$blacklist.markers <- dplyr::bind_rows(res$blacklist.markers, blacklist.markers)
      }
    }
    dups <- blacklist.markers <- whitelist.markers <- i <- new.dups <- NULL
    res$blacklist.markers <- dplyr::distinct(res$blacklist.markers, MARKERS)
    res$whitelist.markers <- NULL
    message("With threshold selected, ", nrow(res$blacklist.markers) ," SNPs blacklisted")
  } else {
    message("With threshold selected, the blacklist of markers in LD is empty")
    res <- list(blacklist.markers = tibble::tibble(MARKERS = character(0)))
  }
  return(res)
} # End ld_pruning
