#' @name snp_ld
#' @title GBS/RADseq short and long distance linkage disequilibrium pruning
#' @description SNP short and long distance linkage disequilibrium pruning.
#'
#' What sets appart radiator LD pruning is the RADseq data tailored arguments.
#' First, minimize short linkage disequilibrium (LD) by
#' choosing between 5 values for \code{snp.ld} argument (see below).
#' Second, you can optionally reduce long distance LD by adjusting the argument
#' \code{ld.threshold}. Values between 0.7 and 0.9 are good starting point.
#' You can also choose to refilter the data using the outlier statistics
#' generated by the function.
#' To prune markers in long distance LD, instead of choosing randomly one SNP,
#' radiator can incorporate missing data statistics
#' to determine the best SNP to keep (see details).
#'
#' Long distance LD pruning is usually advised to avoid capturing the variance LD
#' in PCA analysis.
#'
#' This function is used internally in \href{https://github.com/thierrygosselin/radiator}{radiator}
#' and might be of interest for users.

#' @param data A tidy data set with ID (LOCUS) and POS (SNP) information.
#' \emph{How to get a tidy data frame ?}
#' Look into \pkg{radiator} \code{\link{tidy_genomic_data}}.
#' Usually the LOCUS and POS info is taken from a VCF file.
#'
#' The function also accept \code{SeqVarGDSClass} object generated
#' with the SeqArray package
#' or \pkg{radiator} \code{\link{write_seqarray}}.
#'
#' \strong{Biallelic genotypes required...}


#' @param snp.ld (character) 5 options:
#' \enumerate{
#' \item \code{snp.ld = "random"} for a random selection of 1 SNP on the read,
#' \item \code{snp.ld = "first"} for the first one on the read...,
#' \item \code{snp.ld = "last"} for the last SNP on the read and
#' \item \code{snp.ld = "middle"} for locus with > 2 SNPs/read the option to select at random
#' one SNP between the first and the last SNP on the read. If the locus as <= 2
#' SNPs on the read, the first one is selected. Note that for that last option,
#' the numbers are reported.
#' \item \code{snp.ld = "maf"} will select the SNP on the locus with the maximum global
#' Minor Allele Frequency (MAF).
#' }
#' Default: \code{snp.ld = "maf"}.

#' @param maf.data (path) When \code{snp.ld = "maf"} is selected,
#' to speed up calculations, you can provide
#' the maf information generated by the function \code{\link{filter_maf}} or
#' let this function calculates it from the data (default).
#' Designated alternate allele embedded in the data are not taken for granted
#' and this information is re-computed from the data to get actual
#' minor allele frequency. In this context, to speed up calculations,
#' the MAF is calculated only for locus with multiple SNPs .
#' Default: \code{maf.data = NULL}.
#'
#' @param ld.threshold (optional, double) The threshold to prune SNP based on
#' Long Distance Linkage Disequilibrium.
#' Default: \code{ld.threshold = NULL}.

#' @param filename (optional, character) File name prefix for file written in
#' the working directory.
#' Default: \code{filename = NULL}.

#' @param verbose (optional, logical) The function will write more details.
#' Default: \code{verbose = TRUE}.


#' @param ... (optional) Advance mode that allows to pass further arguments
#' for fine-tuning the function (see details).

#' @inheritParams tidy_genomic_data

#' @export
#' @rdname snp_ld


#' @importFrom stringi stri_replace_all_fixed stri_join
#' @importFrom tibble has_name
#' @importFrom dplyr select distinct group_by sample_n summarise semi_join n_distinct



#' @details The function requires \href{https://github.com/zhengxwen/SNPRelate}{SNPRelate}
#' (see example below on how to install).
#'
#'
#' \strong{Advance mode, using \emph{dots-dots-dots}}
#' \itemize{
#' \item \code{long.ld.missing} (logical) With \code{long.ld.missing = TRUE}.
#' The function first generates long distance LD values between markers with
#' \emph{SNPRelate::snpgdsLDMat}.
#' SNPs in LD will be pruned based on
#' missingness.
#' e.g. if 4 SNPs are in LD, the 1 SNP selected in
#' the end is base on genotyping rate/missingness. If this statistic is equal
#' between the SNPs in LD, 1 SNP is chosen randomly.
#'
#' Using missigness add extra computational time. To speed the analysis when
#' missingness between markers is not an issue, use \code{long.ld.missing = FALSE}.
#' The function will use \emph{SNPRelate::snpgdsLDpruning}
#' to prune the dataset. SNPs in LD are selected randomly.
#' Default: \code{long.ld.missing = FALSE}.
#' \item \code{keep.gds} (logical) Default: \code{keep.gds = FALSE}, when the input data is a
#' tidy data frame of genotypes, the GDS file
#' generated for the long distance LD is removed after completion. With GDS input,
#' the GDS file is always updated and kept in the working directory.
#' \item \code{ld.figures}: (logical) Generate long distance LD statistics and
#' figures.
#' Default: \code{ld.figures = FALSE}
#' \item \code{ld.wide}: (logical) Generate a tibble with the pairwise LD values
#' observed between markers in wide format.
#' Default: \code{ld.wide = FALSE}
#' \item \code{ld.tibble}: (logical) Generate a tibble with the pairwise LD
#' values observed between markers in one column (long format).
#' Default: \code{ld.tibble = FALSE}
#' }
#'
#' @return A list in the global environment, with these objects:
#' \enumerate{
#' \item $ld.wide: a tibble with the pairwise LD values observed between markers in wide format.
#' \item $ld.tibble: a tibble with the pairwise LD values observed between markers in one column (long format).
#' \item $ld.summary: tibble with LD statistics used for the boxplot
#' \item $ld.boxplot: box plot of LD values
#' \item $whitelist.snp.ld: whitelist of markers kept after filtering for LD.
#' The argument \code{ld.threshold} must be used to generate the whitelist.
#' \item $blacklist.snp.ld: blacklist of markers prunned during the filtering
#' for LD.
#' The argument \code{ld.threshold} must be used to generate the blacklist.
#' \item $data: The filtered tidy dataset.
#' \item $gds: the path to the GDS file.
#' }

#' @references Zheng X, Levine D, Shen J, Gogarten SM, Laurie C, Weir BS.
#' (2012) A high-performance computing toolset for relatedness and principal component
#' analysis of SNP data. Bioinformatics. 28: 3326-3328.
#' doi:10.1093/bioinformatics/bts606

#' @seealso \href{https://github.com/zhengxwen/SNPRelate}{SNPRelate}

#' @examples
#' \dontrun{
#' #require(SNPRelate)
#' #To install SNPRelate:
#' #source("https://bioconductor.org/biocLite.R")
#' #biocLite("SNPRelate")
#' #library(radiator)
#' data <- radiator::tidy_vcf(
#' data = "my.vcf", strata = "my.strata.tsv",
#' vcf.metadata = FALSE, vcf.stats = TRUE, verbose = TRUE)
#'
#' # short distance LD, no long distance LD:
#' check.short.ld <- radiator::snp_ld(
#' data = data$tidy.data,
#' snp.ld = "maf")
#'
#' # short distance LD and long distance LD:
#' pruned.ld <- radiator::snp_ld(
#' data = data$tidy.data,
#' snp.ld = "maf", ld.threshold = 0.8)
#' }


#' @author Thierry Gosselin \email{thierrygosselin@@icloud.com}


snp_ld <- function(
  data,
  snp.ld = "maf",
  maf.data = NULL,
  ld.threshold = NULL,
  parallel.core = parallel::detectCores() - 1,
  filename = NULL,
  verbose = TRUE,
  ...
) {

  # # testing
  # data <- res$vcf.connection
  # snp.ld = "maf"
  # maf.data = NULL
  # ld.threshold = 0.8
  # filename = NULL
  # parallel.core = parallel::detectCores() - 1
  # # ...
  # keep.gds <- TRUE
  # ld.figures <- TRUE
  # ld.wide <- FALSE
  # ld.tibble <- FALSE
  # manhattan.plot <- FALSE
  # long.ld.missing = TRUE

  timing <- proc.time()
  opt.change <- getOption("width")
  options(width = 70)
  res.ld <- list()# to store the output

  # dotslist -------------------------------------------------------------------
  radiator.dots <- list(...)
  want <- c("long.ld.missing", "keep.gds", "ld.wide", "ld.tibble", "ld.figures", "manhattan.plot")
  unknowned_param <- setdiff(names(radiator.dots), want)

  if (length(unknowned_param) > 0) {
    stop("Unknowned \"...\" parameters ",
         stringi::stri_join(unknowned_param, collapse = " "))
  }

  long.ld.missing <- radiator.dots[["long.ld.missing"]]
  keep.gds <- radiator.dots[["keep.gds"]]
  ld.wide <- radiator.dots[["ld.wide"]]
  ld.tibble <- radiator.dots[["ld.tibble"]]
  ld.figures <- radiator.dots[["ld.figures"]]
  manhattan.plot <- radiator.dots[["manhattan.plot"]]

  if (is.null(long.ld.missing)) long.ld.missing <- FALSE
  if (is.null(keep.gds)) keep.gds <- FALSE
  if (is.null(ld.wide)) ld.wide <- FALSE
  if (is.null(ld.tibble)) ld.tibble <- FALSE
  if (is.null(ld.figures)) ld.figures <- FALSE
  if (is.null(manhattan.plot)) manhattan.plot <- FALSE
  if (is.null(ld.threshold)) long.ld.missing <- FALSE

  # match arg ------------------------------------------------------------------
  snp.ld <- match.arg(snp.ld, c("first", "random", "last", "middle", "maf"))

  # Checking for missing and/or default arguments ------------------------------
  if (missing(data)) stop("Input file missing")

  # Filename -------------------------------------------------------------------
  file.date <- format(Sys.time(), "%Y%m%d@%H%M")
  if (is.null(filename)) {
    write.ld <- FALSE
    filename <- stringi::stri_join("radiator_", file.date, ".ld")
  } else {
    write.ld <- TRUE
    filename.problem <- file.exists(filename)
    if (filename.problem) {
      filename <- stringi::stri_join(filename, "_", file.date, ".ld")
    } else {
      filename <- stringi::stri_join(filename, ".ld")
    }
  }

  filename.gds <- stringi::stri_join(filename, ".gds")
  # Import data ---------------------------------------------------------------
  data.type <- radiator::detect_genomic_format(data)

  if (data.type == "tbl_df") {
    if (is.vector(data)) {
      data <- radiator::tidy_wide(data = data, import.metadata = FALSE)
    }

    markers <- dplyr::select(data, MARKERS, CHROM, LOCUS, POS) %>%
      dplyr::distinct(MARKERS, .keep_all = TRUE)

    # Check that fiel format as ID and POS -------------------------------------
    if (!tibble::has_name(data, "LOCUS") && !tibble::has_name(data, "POS")) {
      stop("snp.ld is only available for VCF file and/or files with ID and POS info")
    }

    if (!is.null(ld.threshold)) {# for long distance LD pruning
      # Check that snprelate is installed
      if (!requireNamespace("SNPRelate", quietly = TRUE)) {
        stop('To install SNPRelate:\n
         source("https://bioconductor.org/biocLite.R")
         biocLite("SNPRelate")')
      }
      # Check if data is biallelic -------------------------------------------------
      biallelic <- radiator::detect_biallelic_markers(data = data)
      if (!biallelic) stop("Long distance LD: biallelic genotypes required")

      # Generating SNPRelate data --------------------------------------------------
      if (verbose) if (verbose) message("Preparing the data...")
      res.ld$data.gds <- radiator::write_snprelate(
        data = data,
        biallelic = TRUE,
        filename = filename,
        verbose = FALSE)
      if (keep.gds) {
        if (verbose) if (verbose) message("SNPRelate GDS file generated: ", filename.gds)
        if (verbose) if (verbose) message("To close the connection use SNPRelate::snpgdsClose(filename)")
      }
    }
  } else {
    res.ld$data.gds <- data
    data <- markers <- tibble::tibble(
      VARIANT_ID = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.ld$data.gds, path = "radiator/markers.meta/VARIANT_ID")),
      MARKERS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.ld$data.gds, path = "radiator/markers.meta/MARKERS")),
      CHROM = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.ld$data.gds, path = "radiator/markers.meta/CHROM")),
      LOCUS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.ld$data.gds, path = "radiator/markers.meta/LOCUS")),
      POS = gdsfmt::read.gdsn(gdsfmt::index.gdsn(node = res.ld$data.gds, path = "radiator/markers.meta/POS"))
    )
  }

  if (verbose) if (verbose) message("Minimizing short distance LD...")
  if (verbose) if (verbose) message("    snp.ld = ", snp.ld)

  snp.locus <- dplyr::distinct(data, LOCUS, MARKERS, .keep_all = TRUE) %>%
    dplyr::arrange(LOCUS, MARKERS)
  locus.stats <- dplyr::group_by(.data = snp.locus, LOCUS) %>%
    dplyr::tally(.) %>%
    dplyr::rename(SNP_N = n) %>%
    dplyr::group_by(SNP_N) %>%
    dplyr::tally(.)

  if (nrow(locus.stats) > 1) {
    range.number.snp.locus <- range(locus.stats$SNP_N, na.rm = TRUE)
    if (verbose) if (verbose) message("    The range in the number of SNP/locus is: ", stringi::stri_join(range.number.snp.locus, collapse = "-"))
    # Random selection ---------------------------------------------------------
    if (snp.ld == "random") {
      snp.select <- snp.locus %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::sample_n(tbl = ., size = 1, replace = FALSE)
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      n.markers <- stringi::stri_join(snp.before, snp.before - snp.after, snp.after, sep = " / ")
      if (verbose) message("    Number of SNPs before / blacklisted / after: ", n.markers)
    }#End snp random

    # Fist SNP on the read -----------------------------------------------------
    if (snp.ld == "first") {
      snp.select <- snp.locus %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::summarise(POS = min(POS))
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      n.markers <- stringi::stri_join(snp.before, snp.before - snp.after, snp.after, sep = " / ")
      if (verbose) message("    Number of SNPs before / blacklisted / after: ", n.markers)
    }#End snp first

    # Last SNP on the read -----------------------------------------------------
    if (snp.ld == "last") {
      snp.select <- snp.locus %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::summarise(POS = max(POS))
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      n.markers <- stringi::stri_join(snp.before, snp.before - snp.after, snp.after, sep = " / ")
      if (verbose) message("    Number of SNPs before / blacklisted / after: ", n.markers)
    }#End snp last

    # Middle SNP on the read -----------------------------------------------------
    if (snp.ld == "middle") {
      snp.locus.prep <- dplyr::group_by(.data = snp.locus, LOCUS) %>%
        dplyr::tally(.)

      pick.middle <- snp.locus.prep %>%
        dplyr::filter(n > 2) %>%
        dplyr::select(LOCUS)

      if (nrow(pick.middle) == 0) {
        if (verbose) message("IMPORTANT: the data doesn't have more than 3 SNPs per locus")
        if (verbose) message("    First SNP will be selected instead...")
        snp.select <- snp.locus %>%
          dplyr::group_by(LOCUS) %>%
          dplyr::summarise(POS = min(POS))
      } else {

        # For locus with <= 2 SNPs/read just keep the first one.
        keep.first <- snp.locus.prep %>%
          dplyr::filter(n <= 2) %>%
          dplyr::select(LOCUS)
        if (verbose) message("    Number of locus with first SNP selected: ", nrow(keep.first))
        keep.first.select <- snp.locus %>%
          dplyr::filter(LOCUS %in% keep.first$LOCUS) %>%
          dplyr::group_by(LOCUS) %>%
          dplyr::summarise(POS = min(POS))

        pick.middle.select <- snp.locus %>%
          dplyr::filter(LOCUS %in% pick.middle$LOCUS) %>%
          dplyr::group_by(LOCUS) %>%
          dplyr::filter(POS != min(POS)) %>% # remove the first SNP
          dplyr::filter(POS != max(POS)) %>% # remove the last SNP
          dplyr::sample_n(tbl = ., size = 1, replace = FALSE) # pick one at random

        if (verbose) message("    Number of locus with random middle SNP selected: ", nrow(pick.middle))
        snp.select <- dplyr::bind_rows(keep.first.select, pick.middle.select) %>%
          dplyr::arrange(LOCUS, POS)
      }
      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      n.markers <- stringi::stri_join(snp.before, snp.before - snp.after, snp.after, sep = " / ")
      if (verbose) message("    Number of SNPs before / blacklisted / after: ", n.markers)
    }#End snp middle

    # SNP with max MAF on the read -----------------------------------------------
    if (snp.ld == "maf") {
      # snp.select: markers that doesnt require filtering for MAF/MAC
      # because only 1 SNP/locus
      snp.select <- dplyr::group_by(.data = snp.locus, LOCUS) %>%
        dplyr::tally(.) %>%
        dplyr::filter(n == 1) %>%
        dplyr::left_join(snp.locus, by = "LOCUS") %>%
        dplyr::select(-n) %>%
        dplyr::distinct(MARKERS, .keep_all = TRUE)


      if (is.null(maf.data)) {
        if (data.type == "tbl_df") {
          # calculate GLOBAL MAF per SNP/LOCUS
          if (tibble::has_name(data, "GT_BIN")) {
            markers.df <- dplyr::distinct(snp.locus, MARKERS) %>%
              dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS)
            n.markers <- nrow(markers.df)

            global_maf <- function(x) {
              maf.data <- dplyr::group_by(x, MARKERS) %>%
                dplyr::summarise(
                  N = as.numeric(2 * n()),
                  PP = as.numeric(2 * length(GT_BIN[GT_BIN == 0])),
                  PQ = as.numeric(length(GT_BIN[GT_BIN == 1])),
                  QQ = as.numeric(2 * length(GT_BIN[GT_BIN == 2]))
                ) %>%
                # need this step because seen cases where 2 is not the minor allele...
                dplyr::mutate(
                  PP = PP + PQ,
                  QQ = QQ + PQ,
                  ALT = dplyr::if_else(PP < QQ, PP, QQ)) %>%
                dplyr::mutate(
                  MAF_GLOBAL = (ALT / N),
                  N = NULL, PP = NULL, QQ = NULL, PQ = NULL, ALT = NULL) %>%
                dplyr::ungroup(.)

              return(maf.data)
            }#End global_maf

            if (n.markers > 10000) {
              split.vec <- markers.df %>%
                dplyr::mutate(SPLIT_VEC = split_vec_row(
                  markers.df,
                  cpu.rounds = ceiling(n.markers/10000),
                  parallel.core = parallel.core))

              maf.data <- data %>%
                dplyr::filter(!is.na(GT_BIN)) %>%
                dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS) %>%
                dplyr::left_join(split.vec, by = "MARKERS") %>%
                split(x = ., f = .$SPLIT_VEC) %>%
                .radiator_parallel_mc(
                  X = .,
                  FUN = global_maf,
                  mc.cores = parallel.core
                ) %>%
                dplyr::bind_rows(.)
              markers.df <- split.vec <- NULL
            } else {
              maf.data <- global_maf(
                x = dplyr::filter(data, !is.na(GT_BIN)) %>%
                  dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS)
              )
            }
          } else {
            maf.data <- data %>%
              dplyr::filter(GT != "000000") %>%
              dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS) %>%
              dplyr::select(MARKERS, INDIVIDUALS, GT) %>%
              dplyr::mutate(
                A1 = stringi::stri_sub(GT, 1, 3),
                A2 = stringi::stri_sub(GT, 4,6)
              ) %>%
              dplyr::select(MARKERS, INDIVIDUALS, A1, A2) %>%
              tidyr::gather(data = ., key = ALLELES, value = GT, -c(MARKERS, INDIVIDUALS)) %>%
              dplyr::group_by(MARKERS, GT) %>%
              dplyr::tally(.) %>%
              dplyr::group_by(MARKERS) %>%
              dplyr::mutate(n.al.tot = sum(n)) %>%
              dplyr::filter(n == min(n)) %>%
              dplyr::distinct(MARKERS, .keep_all = TRUE) %>%
              dplyr::summarise(MAF_GLOBAL = n / n.al.tot) %>%
              dplyr::ungroup(.) %>%
              dplyr::select(MARKERS, MAF_GLOBAL)
          }

          snp.select.maf <- snp.locus %>%
            dplyr::filter(!MARKERS %in% snp.select.no.maf$MARKERS) %>%
            dplyr::left_join(maf.data, by = "MARKERS") %>%
            dplyr::group_by(LOCUS) %>%
            dplyr::filter(MAF_GLOBAL == max(MAF_GLOBAL)) %>%
            dplyr::ungroup(.) %>%
            dplyr::distinct(LOCUS, .keep_all = TRUE)

        } else {
          # Note to myself: instead of creating a new object (maf.data),
          # include the info in the markers obj
          n.markers <- dplyr::n_distinct(markers$MARKERS)
          markers <- suppressWarnings(
            markers %>%
              dplyr::bind_cols(
                SeqArray::seqAlleleCount(
                  gdsfile = res.ld$data.gds,
                  ref.allele = NULL,
                  .progress = TRUE,
                  parallel = parallel.core) %>%
                  unlist(.) %>%
                  matrix(
                    data = .,
                    nrow = n.markers, ncol = 2, byrow = TRUE,
                    dimnames = list(rownames = markers$MARKERS,
                                    colnames = c("REF_COUNT", "ALT_COUNT"))) %>%
                  tibble::as_tibble(.)) %>%
              dplyr::mutate(
                # MAC or MAF here it's the same
                MAF_GLOBAL = dplyr::if_else(ALT_COUNT < REF_COUNT, ALT_COUNT, REF_COUNT),
                ALT_COUNT = NULL,
                REF_COUNT = NULL)
          )
        }
      } else {
        if (is.vector(maf.data)) {
          markers <- suppressWarnings(
            markers %>%
              dplyr::bind_cols(
                readr::read_tsv(
                  file = maf.data,
                  col_types = readr::cols(.default = readr::col_character())) %>%
                  dplyr::select(MARKERS, MAF_GLOBAL) %>%
                  dplyr::distinct(MARKERS, .keep_all = TRUE)
              ))
        } else {
          markers <- suppressWarnings(
            markers %>%
              dplyr::bind_cols(
                maf.data %>%
                  dplyr::select(dplyr::one_of(c("MARKERS", "MAF_GLOBAL"))) %>%
                  dplyr::distinct(MARKERS, .keep_all = TRUE)))
        }
      }
      # alternative that doesnt require snp.select.maf
      snp.select <- markers %>%
        dplyr::filter(!MARKERS %in% snp.select$MARKERS) %>%
        dplyr::group_by(LOCUS) %>%
        dplyr::filter(MAF_GLOBAL == max(MAF_GLOBAL)) %>%
        dplyr::ungroup(.) %>%
        dplyr::select(-MAF_GLOBAL) %>%
        dplyr::distinct(LOCUS, .keep_all = TRUE) %>%
        dplyr::bind_rows(snp.select)

      snp.before <- nrow(snp.locus)
      snp.after <- nrow(snp.select)
      n.markers <- stringi::stri_join(snp.before, snp.before - snp.after, snp.after, sep = " / ")
      if (verbose) message("    Number of SNPs before / blacklisted / after: ", n.markers)
      snp.locus <- markers <- NULL
    }#End snp maf


    # filtering the VCF to minimize LD -----------------------------------------
    # data <- dplyr::semi_join(data, snp.select, by = c("LOCUS", "POS"))
    if (data.type == "tbl_df") {
      data <- dplyr::filter(data, MARKERS %in% snp.select$MARKERS)
    } else {
      res.ld$whitelist.snp.ld <- snp.select
      res.ld$blacklist.snp.ld <- dplyr::filter(data, !MARKERS %in% snp.select$MARKERS)
      data <- res.ld$whitelist.snp.ld

      # updating the GDS object ------------------------------------------------
      SeqArray::seqSetFilter(object = res.ld$data.gds,
                             variant.id = data$VARIANT_ID,
                             verbose = FALSE)

    }
    # if (verbose) message("    Filtering the dataset to minimize LD by keeping only 1 SNP per locus")
  } else {
    if (verbose) message("    There is no variation in the number of SNP/locus across the data")
    data <- res.ld$whitelist.snp.ld <- snp.locus
    res.ld$blacklist.snp.ld <- NULL
  }
  # Note to myself:
  # locus.stats: this stats could be written in directory or output in res
  snp.select <-  locus.stats <- NULL


  # Long distance LD pruning ---------------------------------------------------
  if (!is.null(ld.threshold)) {
    want <- c("VARIANT_ID", "MARKERS", "CHROM", "LOCUS", "POS")
    markers <- suppressWarnings(
      dplyr::select(data, dplyr::one_of(want)) %>%
        dplyr::distinct(MARKERS, .keep_all = TRUE) %>%
        dplyr::arrange(VARIANT_ID))

    chrom.tick <- dplyr::distinct(markers, CHROM) %>%
      dplyr::mutate(
        CHROM_TICK = stringi::stri_join(seq(from = 1, to = n(), by = 1), n(), sep = "/"))

    markers %<>% dplyr::left_join(chrom.tick, by = "CHROM") %>% dplyr::arrange(VARIANT_ID)

    chrom.tick <- chrom.tick$CHROM
    variant.id.select <- markers %>%
      dplyr::select(VARIANT_ID) %>%
      purrr::flatten_int(.)

    n.markers <- length(variant.id.select)
    # LONG LD with MISSING -----------------------------------------------------
    if (long.ld.missing) {
      if (verbose) message("Long distance LD pruning with missing data")
      chrom.select <- markers %>%
        dplyr::mutate(CHROM = factor(x = CHROM, levels = chrom.tick, ordered = TRUE)) %>%
        split(x = ., f = .$CHROM)
      n.chrom <- length(chrom.select)
      if (verbose) message("Computing LD by CHROM/scaffold (n = ", n.chrom, "), with LD threshold: ", ld.threshold)

      # chrom.select <- chrom.select[1:10]
      # chrom.select <- chrom.select[[9]]

      # if (verbose) message("Pruning markers in long distance LD...")
      # With furrr
      # chrom.ld <- furrr::future_map_dfr(.x = chrom.select,
      #                           .f = ld_chrom_missing,
      #                           x = res.ld$data.gds,
      #                           data.type = data.type,
      #                           ld.threshold = ld.threshold,
      #                           parallel.core = parallel.core,
      #                           verbose = FALSE,
      #                           .progress = TRUE)

      # with purrr:
      chrom.ld <- purrr::map_df(.x = chrom.select,
                                .f = ld_chrom_missing,
                                x = res.ld$data.gds,
                                data.type = data.type,
                                ld.threshold = ld.threshold,
                                parallel.core = parallel.core,
                                verbose = verbose)

      # if (verbose) message("Generating whitelist and blacklist of markers")
      markers %<>%
        dplyr::mutate(
          FILTER_LONG_LD = dplyr::if_else(
            MARKERS %in% chrom.ld$MARKERS, FALSE, TRUE))
      chrom.ld <- NULL
      res.ld$whitelist.snp.ld <- dplyr::filter(markers, FILTER_LONG_LD) %>%
        dplyr::select(-FILTER_LONG_LD)


      if (is.null(res.ld$blacklist.snp.ld)) {
        res.ld$blacklist.snp.ld <- dplyr::filter(markers, !FILTER_LONG_LD) %>%
          dplyr::select(-FILTER_LONG_LD)
      } else {
        res.ld$blacklist.snp.ld  %<>% dplyr::bind_rows(
          dplyr::filter(markers, !FILTER_LONG_LD) %>%
            dplyr::select(-FILTER_LONG_LD))
      }

      n.before <- nrow(markers)
      n.after <- nrow(res.ld$whitelist.snp.ld)
      if (verbose) message("\nNumber of SNPs (before / blacklisted / after) pruning for long distance LD: ",
              n.before, " / ", n.before - n.after, " / ", n.after)

      # updating the GDS object ------------------------------------------------
      if (data.type == "tbl_df") {
        data <- dplyr::filter(data, MARKERS %in% res.ld$whitelist.snp.ld$MARKERS)
      } else {
        SeqArray::seqSetFilter(object = res.ld$data.gds,
                               variant.id = res.ld$whitelist.snp.ld$VARIANT_ID,
                               verbose = FALSE)
      }

    } else {
      # Pruning with SNPRelate::snpgdsLDpruning --------------------------------------
      # problem with this one is that missigness is unaccounted for during SNP selection
      # SNPs are randomly selected...
      if (verbose) message("Long distance LD pruning WITHOUT missing data stats")
      # ld.threshold <- 0.8
      ld.markers <- list()

      # So far test shows that there's no gain in speed to do it in parallel
      # more test with different datasets required (tested 2...)
      # n.chrom <- dplyr::n_distinct(markers$CHROM)

      # if (parallel.core > 1) {
      # prune_ld_par <- function(chrom.snp.select, data, threshold) {
      # pruned.snp <- SNPRelate::snpgdsLDpruning(
      #   gdsobj = data,
      #   snp.id = chrom.snp.select$VARIANT_ID,
      #   autosome.only = FALSE,
      #   remove.monosnp = TRUE,
      #   maf = NaN,
      #   missing.rate = NaN,
      #   method = "r",
      #   ld.threshold = threshold,
      #   num.thread = 1,
      #   verbose = TRUE) %>%
      #   purrr::flatten_int(.)
      # return(pruned.snp)
      # }#End prune_ld_par
      #

      # ld.markers$whitelist.markers <-
      #   split(x = x, f = split.vec) %>%
      #   .radiator_parallel(
      #     X = ., FUN = clean, mc.cores = parallel.core) %>%
      #   purrr::flatten_int(.)

      # sample.chrom <- sample(x = unique(markers$CHROM), size = 11)
      #
      # check <- dplyr::left_join(
      #   dplyr::select(markers, CHROM, VARIANT_ID),
      #   dplyr::distinct(markers, CHROM) %>%
      #     dplyr::mutate(
      #       SPLIT_VEC = split_vec_row(x = ., cpu.rounds = 10, parallel.core = parallel.core)
      #     )
      #   , by = "CHROM") %>%
      #   dplyr::filter(CHROM %in% sample.chrom) %>%
      #   dplyr::select(-CHROM) %>%
      #   split(x = ., f = .$SPLIT_VEC) %>%
      #   .radiator_parallel_mc(
      #     X = .,
      #     FUN = prune_ld_par,
      #     mc.cores = parallel.core,
      #     data = res.ld$data.gds, threshold = ld.threshold
      #   ) %>%
      #   purrr::flatten_int(.)
      # length(unique(check$CHROM))


      ld.markers$whitelist.markers <- SNPRelate::snpgdsLDpruning(
        gdsobj = res.ld$data.gds,
        snp.id = variant.id.select,
        sample.id = SeqArray::seqGetData(res.ld$data.gds, "sample.id"),
        autosome.only = FALSE,
        remove.monosnp = TRUE,
        maf = NaN,
        missing.rate = NaN,
        method = "r",
        ld.threshold = ld.threshold,
        num.thread = 1,
        verbose = FALSE) %>%
        purrr::flatten_int(.)

      ld.markers$blacklist.markers <- purrr::keep(
        .x = variant.id.select,
        .p = !variant.id.select %in% ld.markers$whitelist.markers)
      markers %<>%
        dplyr::mutate(
          FILTER_LONG_LD = dplyr::if_else(
            VARIANT_ID %in% ld.markers$whitelist.markers, TRUE, FALSE))
      ld.markers <- NULL
      res.ld$whitelist.snp.ld <- dplyr::filter(markers, FILTER_LONG_LD)
      if (is.null(res.ld$blacklist.snp.ld)) {
        res.ld$blacklist.snp.ld <- dplyr::filter(markers, !FILTER_LONG_LD)
      } else {
        res.ld$blacklist.snp.ld %<>%
          dplyr::bind_rows(dplyr::filter(markers, !FILTER_LONG_LD))
      }
      n.before <- nrow(markers)
      n.after <- nrow(res.ld$whitelist.snp.ld)
      if (verbose) message("\nNumber of SNPs (before / blacklisted / after) pruning for long distance LD: ",
              n.before, " / ", n.before - n.after, " / ", n.after)
      # updating the GDS object ------------------------------------------------
      if (data.type == "tbl_df") {
        data <- dplyr::filter(data, MARKERS %in% res.ld$whitelist.snp.ld$MARKERS)
      } else {
        SeqArray::seqSetFilter(object = res.ld$data.gds,
                               variant.id = res.ld$whitelist.snp.ld$VARIANT_ID,
                               verbose = FALSE)

      }
    }
  }#End long distance LD pruning

  if (verbose) message("Generating whitelist and blacklist of markers")
  if (verbose) message("\nComputation time for LD: ", round((proc.time() - timing)[[3]]), " sec")
  options(width = opt.change)

  if (data.type == "tbl_df") {
    return(data)
  } else {
    return(res.ld)
  }
}#End snp_ld


# Internal nested functions: ---------------------------------------------------

# melt the LD matrice into a data frame --------------------------------------
#' @title ld2df
#' @description melt the LD matrice into a data frame
#' @rdname ld2df
#' @export
#' @keywords internal
ld2df <- function(x) {
  x <- as.matrix(x)
  x <- dplyr::bind_cols(tibble::data_frame(MARKERS_A = rownames(x)),
                        tibble::as_data_frame(x)) %>%
    data.table::as.data.table(.) %>%
    data.table::melt.data.table(
      data = ., id.vars = "MARKERS_A", variable.name = "MARKERS_B", value.name = "LD",
      variable.factor = FALSE) %>%
    tibble::as_data_frame(.) %>%
    dplyr::filter(!is.na(LD)) %>%
    dplyr::arrange(dplyr::desc(LD))
  return(x)
}#End distance2df

# ld_pruning  ------------------------------------------------------------------

#' @name ld_pruning
#' @title Prune dataset based on LD.
#' @description Used internally in \href{https://github.com/thierrygosselin/radiator}{radiator}
#' Prune dataset based on LD.

#' @param ld.tibble (path) The markers LD pairwise data.
#' Default: \code{ld.tibble = NULL}.
#' @param stats (path) The markers missingness info statistics.
#' Default: \code{stats = NULL}.
#' @param ld.threshold (double) The threshold to prune SNPs in LD.
#' Default: \code{ld.threshold = 0.8}.
#' @param verbose (logical, optional) Default: \code{verbose = TRUE}.
#' @return A list with blacklisted SNPs.  Write the blacklist in the working
#' directory.
#' @export
#' @keywords internal
#' @rdname remove_duplicates
#' @author Thierry Gosselin \email{thierrygosselin@@icloud.com}

ld_pruning <- function(
  ld.tibble = NULL,
  stats = NULL,
  ld.threshold = 0.8,
  verbose = TRUE
) {
  #test
  # ld.tibble = res$ld.tibble
  # stats = res$markers.missing
  # ld.threshold = 0.8

  ld.tibble <- dplyr::filter(ld.tibble, LD > ld.threshold)

  if (nrow(ld.tibble) > 0) {
    markers.ld.list <- tibble::data_frame(
      MARKERS = c(ld.tibble$MARKERS_A, ld.tibble$MARKERS_B)) %>%
      dplyr::group_by(MARKERS) %>%
      dplyr::tally(.) %>%
      dplyr::ungroup(.) %>%
      dplyr::arrange(dplyr::desc(n)) %>%
      dplyr::distinct(MARKERS) %>%
      purrr::flatten_chr(.)

    # test <- unique(c(ld.tibble$MARKERS_A, ld.tibble$MARKERS_B))
    # we want to have them ordered from highest to lowest hence the appraoch above...

    geno.stats <- dplyr::filter(stats, MARKERS %in% markers.ld.list)

    res <- list(blacklist.markers = tibble::tibble(MARKERS = character(0)),
                whitelist.markers = tibble::tibble(MARKERS = character(0)))

    for (i in markers.ld.list) {
      # i <- markers.ld.list[1]
      dups <- dplyr::filter(ld.tibble, MARKERS_A %in% i | MARKERS_B %in% i)
      dups <- sort(unique(c(dups$MARKERS_A, dups$MARKERS_B)))

      # find all duplicates associated with the network
      new.dups <- 0L
      while(length(new.dups) > 0) {
        new.dups <- dplyr::filter(ld.tibble, MARKERS_A %in% dups | MARKERS_B %in% dups)
        new.dups <- sort(unique(c(new.dups$MARKERS_A, new.dups$MARKERS_A)))
        new.dups <- purrr::keep(.x = new.dups, .p = !new.dups %in% dups)
        if (length(new.dups) > 0) {
          dups <- c(dups, new.dups)
        }
      }
      dups <- tibble::data_frame(MARKERS = dups)

      if (nrow(res$blacklist.markers) > 0) {
        dups <- dplyr::filter(dups, !MARKERS %in% res$blacklist.markers$MARKERS)
      }

      if (nrow(dups) > 0) {
        whitelist.markers <- dups %>%
          dplyr::left_join(geno.stats, by = "MARKERS") %>%
          dplyr::filter(GENOTYPED_PROP == max(GENOTYPED_PROP)) %>%
          dplyr::sample_n(tbl = ., size = 1) %>% # make sure only 1 is selected
          dplyr::select(MARKERS)

        if (nrow(whitelist.markers) > 0) res$whitelist.markers %<>% dplyr::bind_rows(whitelist.markers)

        blacklist.markers <- dplyr::filter(dups, !MARKERS %in% whitelist.markers$MARKERS) %>%
          dplyr::select(MARKERS)

        if (nrow(blacklist.markers) > 0) res$blacklist.markers %<>% dplyr::bind_rows(blacklist.markers)
      }
    }
    dups <- blacklist.markers <- whitelist.markers <- i <- new.dups <- NULL
    res$blacklist.markers <- dplyr::distinct(res$blacklist.markers, MARKERS)
    res$whitelist.markers <- NULL
    if (verbose) message("    SNPs blacklisted: ", nrow(res$blacklist.markers))

  } else {
    if (verbose) message("    SNPs blacklisted: 0")
    res <- list(blacklist.markers = tibble::tibble(MARKERS = character(0)))
  }
  return(res)
} # End ld_pruning


# ld_chrom_missing  ------------------------------------------------------------------

#' @name ld_chrom_missing
#' @title Prune dataset based on LD and missingness.
#' @description Used internally in \href{https://github.com/thierrygosselin/radiator}{radiator}
#' Prune dataset based on LD, uses missingness to keep 1 SNP. This is the function
#' that does it for 1 chrom. It's then used with purrr::map to run seriall on all chrom.
#' @param chrom.select The split dataset by chromosome.
#' @param x The GDS object.
#' @param data.type The type of dataset.
#' @param ld.threshold The LD threshold.
#' @param parallel.core The number of CPU.
#' @param verbose (logical, optional) Default: \code{verbose = TRUE}.
#' @return A list with blacklisted SNPs.
#' @export
#' @keywords internal
#' @rdname remove_duplicates
#' @author Thierry Gosselin \email{thierrygosselin@@icloud.com}

ld_chrom_missing <- function(chrom.select,
                             x,
                             data.type,
                             ld.threshold,
                             parallel.core = parallel::detectCores() - 1,
                             verbose = TRUE) {
  if (verbose) message("Chrom: ", unique(chrom.select$CHROM), " SNPs number: ", length(chrom.select$VARIANT_ID), "    (", unique(chrom.select$CHROM_TICK), ")")

  # save the filters------------------------------------------------------
  w.m <- SeqArray::seqGetData(x, "variant.id")
  w.s <- SeqArray::seqGetData(x, "sample.id")

  # Adjusting the parallel.core argument ---------------------------------
  # SNPRelate doesnt like when lower than number of markers used...
  parallel.core.temp <- max(1L, length(chrom.select$MARKERS))
  if (parallel.core <= parallel.core.temp) {
    parallel.core.temp <- parallel.core
  }

  if (nrow(chrom.select) > 1) {
    res.chrom <- SNPRelate::snpgdsLDMat(
      gdsobj = x,
      snp.id = chrom.select$VARIANT_ID,
      sample.id = w.s,
      slide = -1,
      mat.trim = FALSE,
      method = "r", #composite and corr option are the same with 0, 1, 2 gt coding
      num.thread = parallel.core.temp,
      with.id = TRUE,
      verbose = FALSE) %$%
      LD %>%
      magrittr::set_colnames(x = ., chrom.select$MARKERS) %>%
      magrittr::set_rownames(x = ., chrom.select$MARKERS)

    # The function SNPRelate::snpgdsLDMat also set the filter
    # to the chosen markers and samples...
    # check <- SeqArray::seqGetFilter(x)
    # length(check$sample.sel[check$sample.sel])
    # length(check$variant.sel[check$variant.sel])
    # n.markers


    # work on the output ---------------------------------------------------------
    # long.distance.ld <- long.distance.ld^2

    # Full matrix
    # if (ld.wide) {
    #   # generate a tibble
    #   filename.ld.wide <- stringi::stri_join(filename, ".wide")
    #   if (verbose) message("Writing LD wide tibble file: ", filename.ld.wide)
    #   radiator::write_rad(
    #     data = dplyr::bind_cols(tibble::data_frame(
    #       MARKERS_A = rownames(res.ld$ld.tibble)),
    #       tibble::as_data_frame(res.ld$ld.tibble)),
    #     path = filename.ld.wide)
    # }

    # LD tibble long...
    # Here we want the tibble in long format with LD values in one column
    # if (verbose) message("Generating LD tibble...")
    # we don't need the full matrix
    res.chrom[lower.tri(res.chrom, diag = TRUE)] <- rlang::na_dbl

    # stats and figures----------------------------------------------------------------------
    # if (ld.figures) {
    #   if (verbose) message("Generating statistics")
    #   res.ld$ld.summary <- tibble::tibble(
    #     LD = as.vector(res.ld$ld.tibble[!is.na(res.ld$ld.tibble)])) %>%
    #     dplyr::summarise(
    #       MIN = min(LD, na.rm = TRUE),
    #       Q25 = stats::quantile(LD, 0.25, na.rm = TRUE),
    #       MEDIAN = stats::median(LD, na.rm = TRUE),
    #       Q75 = stats::quantile(LD, 0.75, na.rm = TRUE),
    #       MAX = max(LD, na.rm = TRUE),
    #       IQR = stats::IQR(LD, na.rm = TRUE)
    #     ) %>%
    #     dplyr::mutate(
    #       OUTLIERS_LOW = Q25 - (1.5 * IQR),
    #       OUTLIERS_HIGH =  Q75 + (1.5 * IQR),
    #       GROUP = 1
    #     )
    #
    #   if (res.ld$ld.summary$OUTLIERS_LOW < 0) {
    #     res.ld$ld.summary$OUTLIERS_LOW <- res.ld$ld.summary$MIN
    #   }
    #
    #   if (verbose) message("Generating figures...")
    #   res.ld$ld.boxplot <- boxplot_stats(
    #     data = res.ld$ld.summary,
    #     title = "Markers long distance linkage disequilibrium (LD)",
    #     x.axis.title = NULL,
    #     y.axis.title = "Long distance linkage disequilibrium (r)",
    #     bp.filename = "ld.boxplot.pdf")
    #
    #   # res.ld$ld.no.outliers.tibble <- dplyr::filter(res.ld$ld.tibble, LD < res.ld$ld.summary$OUTLIERS_HIGH & LD > res.ld$ld.summary$OUTLIERS_LOW)
    #
    #   # Note to myself : interesting but not sure worth the time exploring...
    #
    #
    #   # res.ld$ld.no.outliers.summary <- tibble::tibble(
    #   #   x = 1,
    #   #   MIN = min(res.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
    #   #   Q25 = stats::quantile(res.ld$ld.no.outliers.tibble$LD, 0.25, na.rm = TRUE),
    #   #   MEDIAN = stats::median(res.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
    #   #   Q75 = stats::quantile(res.ld$ld.no.outliers.tibble$LD, 0.75, na.rm = TRUE),
    #   #   MAX = max(res.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
    #   #   IQR = stats::IQR(res.ld$ld.no.outliers.tibble$LD, na.rm = TRUE),
    #   #   OUTLIERS_LOW = Q25 - (1.5 * IQR),
    #   #   OUTLIERS_HIGH =  Q75 + (1.5 * IQR)
    #   # )
    #   # if (res.ld$ld.no.outliers.summary$OUTLIERS_LOW < 0) res.ld$ld.no.outliers.summary$OUTLIERS_LOW <- res.ld$ld.no.outliers.summary$MIN
    #   #
    #   # element.text <- ggplot2::element_text(size = 10,
    #   #                                       family = "Helvetica", face = "bold")
    #   #
    #   # res.ld$ld.boxplot.no.outliers <- ggplot2::ggplot(
    #   #   data = res.ld$ld.no.outliers.summary, ggplot2::aes(x)) +
    #   #   ggplot2::geom_boxplot(
    #   #     ggplot2::aes(ymin = MIN, lower = Q25, middle = MEDIAN,
    #   #                  upper = Q75, ymax = MAX), stat = "identity") +
    #   #   ggplot2::labs(
    #   #     y = "Long distance linkage disequilibrium",
    #   #     title = "Markers long distance linkage disequilibrium (LD)") +
    #   #   ggplot2::theme_bw() +
    #   #   ggplot2::theme(
    #   #     plot.title = ggplot2::element_text(size = 12, family = "Helvetica", face = "bold", hjust = 0.5),
    #   #     legend.position = "none",
    #   #     axis.title.x = ggplot2::element_blank(),
    #   #     axis.title.y = element.text,
    #   #     axis.text.x = ggplot2::element_blank(),
    #   #     axis.ticks.x = ggplot2::element_blank()
    #   #   )
    #   # element.text <- NULL
    #   # print(res.ld$ld.boxplot.no.outliers)
    #   # suppressMessages(ggplot2::ggsave(
    #   #   filename = "ld.no.outliers.boxplot.pdf",
    #   #   # filename = file.path(path.folder.coverage, "plot.coverage.boxplot.pdf"),
    #   #   plot = res.ld$ld.boxplot.no.outliers,
    #   #   width = 15, height = 20,
    #   #   dpi = 300, units = "cm", useDingbats = FALSE))
    #
    #
    #   # res.ld$ld.manhattan.plot
    #   # if (manhattan.plot) {
    #   #   res.ld$ld.manhattan.plot <- res.ld$ld.tibble %>%
    #   #     # dplyr::mutate(X = "1") %>%
    #   #     dplyr::group_by(LD) %>%
    #   #     dplyr::tally(.) %>%
    #   #     dplyr::ungroup(.) %>%
    #   #     dplyr::mutate(X = "1") %>%
    #   #     ggplot2::ggplot(data = .,
    #   #                     ggplot2::aes(x = X, y = LD, size = n)) +
    #   #     ggplot2::geom_jitter(alpha = 0.3, stat = "identity") +
    #   #     ggplot2::labs(y = "LD") +
    #   #     ggplot2::scale_size_area(name = "Pairs of markers", max_size = 6) +
    #   #     ggplot2::theme_light() +
    #   #     ggplot2::theme(
    #   #       # legend.position = "none",
    #   #       panel.grid.minor.x = ggplot2::element_blank(),
    #   #       panel.grid.major.x = ggplot2::element_blank(),
    #   #       # panel.grid.major.y = element_blank(),
    #   #       axis.title.x = ggplot2::element_blank(),
    #   #       axis.text.x = ggplot2::element_blank(),
    #   #       axis.title.y = ggplot2::element_text(size = 10, family = "Helvetica", face = "bold"),
    #   #       axis.text.y = ggplot2::element_text(size = 8, family = "Helvetica")
    #   #     )
    #   #
    #   #   suppressMessages(ggplot2::ggsave(
    #   #     filename = "ld.manhattan.plot.png",
    #   #     plot = res.ld$ld.manhattan.plot,
    #   #     width = 15, height = 20,
    #   #     dpi = 100, units = "cm"#useDingbats = FALSE
    #   #   ))
    #   # }
    # }#End ld.figures

    # Generate the missingness stats -----------------------------------------
    # if (verbose) message("Generate missingness stats")
    if (data.type == "tbl_df") {
      if (tibble::has_name(x, "GT")) {
        markers.missing <- dplyr::filter(x, GT != "000000") %>%
          dplyr::group_by(MARKERS) %>%
          dplyr::summarise(GENOTYPED_PROP = length(GT) / n.ind)
      } else {
        markers.missing <- dplyr::filter(x, !is.na(GT_BIN)) %>%
          dplyr::group_by(MARKERS) %>%
          dplyr::summarise(GENOTYPED_PROP = length(GT_BIN) / n.ind)
      }
    } else {
      markers.missing <- tibble::tibble(
        MARKERS = chrom.select$MARKERS,
        MISSING_PROP = SeqArray::seqMissing(
          gdsfile = x,
          per.variant = TRUE, .progress = TRUE, parallel = parallel.core.temp)) %>%
        dplyr::mutate(GENOTYPED_PROP = 1 - MISSING_PROP, MISSING_PROP = NULL)
    }

    # Pruning the SNPs -------------------------------------------------------
    # if (verbose) message("Pruning markers in long distance LD...")

    # These LD values are not used anyway during the pruning
    res.chrom[res.chrom <= ld.threshold] <- rlang::na_dbl
    # remove rows and cols with all missing values
    res.chrom <- res.chrom[rowSums(res.chrom, na.rm = TRUE) > 0, colSums(res.chrom, na.rm = TRUE) > 0, drop = FALSE]

    if (length(res.chrom) >= 1) {
      res.chrom <- ld2df(x = res.chrom)
      ld.markers <- ld_pruning(
        ld.tibble = res.chrom,
        stats = markers.missing,
        ld.threshold = ld.threshold
      )
    } else {
      if (verbose) message("    SNPs blacklisted: 0")
      ld.markers <- list(blacklist.markers = NULL)
    }
  } else {
    if (verbose) message("    SNPs blacklisted: 0")
    ld.markers <- list(blacklist.markers = NULL)
  }
  # Reset the filter of the GDS-------------------------------------------
  SeqArray::seqSetFilter(object = x, variant.id = w.m, sample.id = w.s,
                         verbose = FALSE)
  return(ld.markers$blacklist.markers)
}#End ld_chrom_missing
